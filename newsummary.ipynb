{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將資料由pymongo讀取近來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #登入pymongo\n",
    "# clinet=pymongo.MongoClient(\"mongodb://10.120.27.23:27017/\")\n",
    "# #確認裡面有哪幾個database\n",
    "# clinet.database_names()\n",
    "# #選擇rawData這個db\n",
    "# db=clinet['rawData']\n",
    "# #確認裡面有哪幾個collection\n",
    "# db.collection_names()\n",
    "# #將愛評網讀入\n",
    "# ipeenjson=list(db.Tainan_final.find({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " # 或直接讀取json檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'./data/final_tainan.json') as f:\n",
    "    ipeenjson=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipeenjson[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將結巴字典加入自己的許多詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#結巴 匯入自己的詞典\n",
    "jieba.set_dictionary('./dict/jieba_dict.txt.big')\n",
    "\n",
    "#停止詞字典stopwordset\n",
    "stopwordset = set()\n",
    "with open('./dict/stopwords.txt', 'r', encoding='utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "#店家名稱字典dienlist\n",
    "dienlist = [dien[\"name\"] for dien in ipeenjson]\n",
    "\n",
    "#店家種類字典stylelist\n",
    "stylelist = [dien[\"style\"] for dien in ipeenjson]\n",
    "\n",
    "#店家種類字典introductionlist\n",
    "introductionlist = [dien[\"introduction\"] for dien in ipeenjson]\n",
    "\n",
    "#店家種類字典coordinatelist\n",
    "coordinatelist = [dien['coordinate'] for dien in ipeenjson]\n",
    "\n",
    "#自製餐廳相關字字典pinlist\n",
    "with open(\"./dict/MyDict.csv\") as f:\n",
    "    mydict=f.read()\n",
    "#linewords pindict每個字的評分dict\n",
    "linewords=[{myword:float(line.split(\",\")[0]) for myword in line.split(\",\")[1:]}\\\n",
    "           for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\"]\n",
    "pindict={}\n",
    "for word in linewords:\n",
    "    pindict.update(word)\n",
    "pinlist=list(pindict.keys())\n",
    "\n",
    "#將以上字典都加入斷詞行列\n",
    "for i in dienlist:\n",
    "    jieba.add_word(i)\n",
    "for i in stylelist:\n",
    "    jieba.add_word(i)\n",
    "for i in pinlist:\n",
    "    if i !=\"\":\n",
    "        jieba.add_word(i)\n",
    "        \n",
    "#店家評論總數Ncommentlist\n",
    "Ncommentlist = [len(i[\"comment\"]) for i in ipeenjson]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各店家評論diencommentlist\n",
    "diencommentlist=[[j[\"content\"] for j in i[\"comment\"]] for i in ipeenjson]\n",
    "diencommentlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#各店家回覆dienmessagelist\n",
    "dienmessagelist=[[''.join(j[\"message\"]) for j in i[\"comment\"] if j[\"message\"]!=None and j[\"message\"]!='null'] for i in ipeenjson]\n",
    "dienmessagelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#回覆數量\n",
    "Nmessagelist=[len(dienmessage) for dienmessage in dienmessagelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全部回覆+全部評論\n",
    "dienallpinlist=[diencomment+dienmessage for diencomment,dienmessage in zip(diencommentlist,dienmessagelist)]\n",
    "dienallpinlist[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for megs in dienmessagelist:\n",
    "#     for meg in megs:\n",
    "#         if meg!=None and meg!='null'and meg!='':\n",
    "#             print(\" \".join(meg))\n",
    "\n",
    "#把所有回覆合併\n",
    "messagecombinlist=[\" \".join([\"\".join(meg) for meg in megs if meg!=None and meg!='null'and meg!='']) for megs in dienmessagelist]\n",
    "messagecombinlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#把所有評論合併\n",
    "commentcombinelist = [\" \".join([j[\"content\"] for j in i[\"comment\"]]) for i in ipeenjson]\n",
    "commentcombinelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#合併評論+回覆\n",
    "pincombinelist=[comment+\" \"+message for comment,message in zip(commentcombinelist,messagecombinlist)]\n",
    "pincombinelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清一下記憶體\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 將許多可能會用來分析的項目做成list\n",
    "\n",
    "# 做TD-IDF分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "st=time.time()\n",
    "#取得各店家的斷完詞評論pincutlist\n",
    "pincutlist = []\n",
    "cutcount=0\n",
    "for pincombine in pincombinelist:\n",
    "    cutcount+=1\n",
    "    if cutcount%200==0:\n",
    "        print(\"以切\"+str(cutcount)+\"篇文章的詞\")\n",
    "    words = jieba.cut(pincombine, cut_all=False)\n",
    "    pincut=\" \".join([word for word in words if word not in stopwordset and '\\u4e00' <= word and word <= '\\u9fff'])\n",
    "    pincutlist.append(pincut)\n",
    "    \n",
    "#所有店家的用詞加總前三百wordCountlist300\n",
    "wordCountlist=[Counter(pincut.split(\" \")).most_common(300) for pincut in pincutlist]\n",
    "\n",
    "#TF計算 (TF=這個字出現的次數/這篇文章的總字數)\n",
    "#(sum(dict(wordCount).values())=>一篇所有字的字數  wordkv[1]>>該文字字數  wordkv[0]>>該文字)\n",
    "#TFList每篇文章的詞 的詞頻\n",
    "TFList=[[((wordkv[0],wordkv[1]/sum(dict(wordCount).values()))) for wordkv in wordCount] for wordCount in wordCountlist]\n",
    "\n",
    "\n",
    "#全文章共用了幾個詞(set可以去除重複，可迭代)\n",
    "wordlist=[]\n",
    "for wordCount in wordCountlist:\n",
    "    for word in wordCount:\n",
    "        wordlist.append(word[0])\n",
    "wordlist=set(wordlist)\n",
    "\n",
    "#nDien所有的文章(店家)數\n",
    "ndien=len(dienlist)\n",
    "\n",
    "#wordappear計算每個字出現於 (幾篇) 文章\n",
    "wordappear={}\n",
    "appearcount=0\n",
    "for word in wordlist:\n",
    "    appearcount+=1\n",
    "    if appearcount%1000==0:\n",
    "        print(\"以計算\"+str(appearcount)+\"個文字的出現篇數\")\n",
    "    n=0\n",
    "    for pincut in pincutlist:\n",
    "        if word in pincut:\n",
    "            n+=1\n",
    "    wordappear[word]=n\n",
    "    \n",
    "#IDF(逆向檔案頻率)=某詞  所有文章數/在幾篇文章出現 開log10 >>次方數為所\n",
    "IDFlist={word:math.log(ndien/wordappear[word],10) for word in wordappear}\n",
    "\n",
    "#dienTF每家店的全字TF值 wordTF每個詞的TF   wordTF[0]詞 wordTF[1]詞的TF值  IDFlist[wordTF[0]]詞的IDF值\n",
    "TF_IDFlist=[Counter({wordTF[0]:wordTF[1]*IDFlist[wordTF[0]]for wordTF in dienTF})for dienTF in TFList]\n",
    "for name,TFIDF in zip(dienlist,TF_IDFlist):\n",
    "    if name in TFIDF:\n",
    "        del TFIDF[name]\n",
    "\n",
    "\n",
    "et=time.time()\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將上面的斷詞文章combine在一起 做word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#將所有的斷詞文章combine在一起，變成超大斷詞字串，並存起來\n",
    "contentcutcombine=\" \".join(pincutlist)\n",
    "with open('./data/TainanContent.txt','w',encoding=\"utf-8\") as w:\n",
    "    w.write(contentcutcombine)\n",
    "    \n",
    "#將存起來的文章用word2vec.Text8Corpus切成有順序的詞彙list(sentences)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus(\"./data/TainanContent.txt\")\n",
    "\n",
    "#將有順序的詞彙list丟給word2vec做訓練\n",
    "model = word2vec.Word2Vec(sentences, size=300,window=6, min_count=4, workers=4,sg=1)\n",
    "# sentences:當然了，這是要訓練的句子集，沒有他就不用跑了\n",
    "# size:這表示的是訓練出的詞向量會有幾維\n",
    "# alpha:機器學習中的學習率，這東西會逐漸收斂到 min_alpha\n",
    "# sg:sg=1表示採用skip-gram(由本字去測他字 擴散),sg=0表示採用cbow(由他字測本字 集中)\n",
    "# window:能往左往右看幾個字的意思\n",
    "# workers:執行緒數目，除非電腦不錯，不然建議別超過 4\n",
    "# min_count:若這個詞出現的次數小於min_count，那他就不會被視為訓練對象\n",
    "\n",
    "# Save our model.\n",
    "model.save(\"./data/Tainan.model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試玩word2vec的model  需解除#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from gensim.models import word2vec\n",
    "# from gensim import models\n",
    "# import logging\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# model = models.Word2Vec.load('.\\data\\Tainan.model.bin')\n",
    "\n",
    "# print(\"提供 3 種測試模式\\n\")\n",
    "# print(\"輸入一個詞，則去尋找前一百個該詞的相似詞\")\n",
    "# print(\"輸入兩個詞，則去計算兩個詞的餘弦相似度\")\n",
    "# print(\"輸入三個詞，進行類比推理\")\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         query = input()\n",
    "#         q_list = query.split()\n",
    "\n",
    "#         if len(q_list) == 1:\n",
    "#             print(\"相似詞前 30 排序\")\n",
    "#             res = model.most_similar(q_list[0],topn = 30)\n",
    "#             for item in res:\n",
    "#                 print(item[0]+\",\"+str(item[1]))\n",
    "\n",
    "#         elif len(q_list) == 2:\n",
    "#             print(\"計算 Cosine 相似度\")\n",
    "#             res = model.similarity(q_list[0],q_list[1])\n",
    "#             print(res)\n",
    "#         else:\n",
    "#             print(\"%s之於%s，如%s之於\" % (q_list[0],q_list[2],q_list[1]))\n",
    "#             res = model.most_similar([q_list[0],q_list[1]], [q_list[2]], topn= 20)\n",
    "#             for item in res:\n",
    "#                 print(item[0]+\",\"+str(item[1]))\n",
    "#         print(\"----------------------------\")\n",
    "#     except Exception as e:\n",
    "#         print(repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試Rocchio、bayes、kmeans、SVM分群 (仿白話大數據寫法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取得各店家的斷完詞評論contentcutlist\n",
    "#店家種類字典stylelist\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#斷詞function\n",
    "def cut_text_list(textlist):\n",
    "    textcutlist=[]\n",
    "    for text in textlist:\n",
    "        cutwords=jieba.cut(text)\n",
    "        cuttext=\" \".join([word for word in cutwords if word not in stopwordset and '\\u4e00' <= word <= '\\u9fff'])\n",
    "        textcutlist.append(cuttext)\n",
    "    return textcutlist\n",
    "\n",
    "#文字轉向量矩陣\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(pincutlist)\n",
    "print('文字轉向量矩陣')\n",
    "\n",
    "#向量矩陣做tfidf\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print('tfidf')\n",
    "\n",
    "\n",
    "\n",
    "#ptt測試集|\n",
    "with open('./data/foodptt.json') as f:\n",
    "    testdatas=json.load(f)\n",
    "docs_new=cut_text_list(testdatas)\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "#試用Roccio分群\n",
    "# from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "st=time.time()\n",
    "clf = NearestCentroid().fit(X_train_tfidf,stylelist)\n",
    "predicted =clf.predict(x_new_tfidf)\n",
    "print(\"Roccio\")\n",
    "pprint.pprint(predicted)\n",
    "ed=time.time()\n",
    "print(ed-st)\n",
    "\n",
    "\n",
    "#試用bayes分群\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "st=time.time()\n",
    "clf = MultinomialNB().fit(X_train_tfidf,stylelist)\n",
    "predicted =clf.predict(x_new_tfidf)\n",
    "print(\"bayes\")\n",
    "pprint.pprint(predicted)\n",
    "ed=time.time()\n",
    "print(ed-st)\n",
    "\n",
    "#試用kmeans分群\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "st=time.time()\n",
    "clf = KNeighborsClassifier(15).fit(X_train_tfidf,stylelist)\n",
    "predicted =clf.predict(x_new_tfidf)\n",
    "print(\"Kmeans\")\n",
    "pprint.pprint(predicted)\n",
    "ed=time.time()\n",
    "print(ed-st)\n",
    "\n",
    "#試用svm分群\n",
    "# from sklearn import svm\n",
    "st=time.time()\n",
    "clf = svm.SVC(kernel=\"linear\").fit(X_train_tfidf,stylelist)\n",
    "predicted =clf.predict(x_new_tfidf)\n",
    "print(\"svm\")\n",
    "pprint.pprint(predicted)\n",
    "ed=time.time()\n",
    "print(ed-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己肉眼辨識的答案是 合菜 美式 義式 西點 鍋類 冰品 臭豆腐 其他 義式 美式 小吃 泰式 台菜\n",
    "\n",
    "# 最準的是 Roccio > svm > kmeans > bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#參考PTT斷詞文章\n",
    "docs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dienallpinlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試者用自己的字典給店家分數(一篇評論的正負評價詞最多算5個)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#各店家評論diencommentlist\n",
    "#取得各店家的斷完詞評論contentcutlist\n",
    "#自製餐廳相關字字典pinlist\n",
    "#pindict每個字的評分dict\n",
    "#各店家評論diencommentlist\n",
    "\n",
    "#pinCountMaxper5list 一個店家出現的餐廳相關詞數量(一個篇評論的相同詞最多給5個分數)\n",
    "st=time.time()\n",
    "pinCountMaxper5list = []\n",
    "countN=0\n",
    "for dienallpin in dienallpinlist:\n",
    "    dienWordcount={}\n",
    "    for allpin in  dienallpin:\n",
    "        countN+=1\n",
    "        if countN%100==0:\n",
    "            print(\"已算完\"+str(countN)+\"篇情緒字\")\n",
    "        for pinword in pinlist:\n",
    "            if len(re.findall(pinword,allpin))>0:\n",
    "                if len(re.findall(pinword,allpin))>5:\n",
    "                    npinword=5\n",
    "                else:\n",
    "                    npinword=len(re.findall(pinword,allpin))\n",
    "                if pinword not in dienWordcount:\n",
    "                    dienWordcount[pinword]=0\n",
    "                dienWordcount[pinword]+=npinword\n",
    "    pinCountMaxper5list.append(dienWordcount)\n",
    "ed=time.time()\n",
    "print(ed-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinCountMaxper5list[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#店家評論總數Ncommentlist\n",
    "#店家回覆總數Nmessage\n",
    "#將六篇回覆視為一篇文章，做正規化(防止評論數過多的店家分數極端化)\n",
    "Npartpin=[int(Nmessage/6)+Ncomment for Nmessage,Ncomment in zip(Nmessagelist,Ncommentlist)]\n",
    "\n",
    "\n",
    "#大致計算每家店的分數dienscorelist\n",
    "dienscorelist=[]\n",
    "for pinCount,N in zip(pinCountMaxper5list,Npartpin):\n",
    "    dienscore=0\n",
    "    for pin in pinCount:\n",
    "        dienscore+=pinCount[pin]*pindict[pin]/N\n",
    "    dienscorelist.append(dienscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dienscorelist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mydict為自己的字典的資料\n",
    "#格式為:\n",
    "######否開頭tag 為 非否tag 反義\n",
    "#給予正分數 tag評價詞(非否評價) 同意字群同意字群同意字群同意字群同意字群同意字群\n",
    "#給予負分數 tag評價詞(否開頭評價) 同意字群同意字群同意字群同意字群同意字群同意字群\n",
    "#給予正分數 tag評價詞(非否評價) 同意字群同意字群同意字群同意字群同意字群同意字群\n",
    "#給予負分數 tag評價詞(否開頭評價) 同意字群同意字群同意字群同意字群同意字群同意字群\n",
    "\n",
    "#line.split(\",\")[1]為tag!!! word為與tag對應的同義字\n",
    "synonyms=[{word:line.split(\",\")[1] for word in line.split(\",\")[1:]} for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\"]\n",
    "\n",
    "pinsynonymsdict={}\n",
    "for synonym in synonyms:\n",
    "    pinsynonymsdict.update(synonym)\n",
    "del pinsynonymsdict[\"\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinsynonymsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#每篇文章pinCountMaxper5list評價詞出現次數\n",
    "#評價同義詞pinsynonymsdict\n",
    "\n",
    "#取得各餐廳的評價特徵分數featurescores!!!\n",
    "featurescores=[]\n",
    "\n",
    "#將評價詞加總及評論次數做iterate\n",
    "for pinCountMaxper5,N in zip(pinCountMaxper5list,Npartpin):\n",
    "    dienfeaturescore={}\n",
    "    \n",
    "    # 評價詞出現次數/評論次數 做為分數，其中否字開頭給負分\n",
    "    for pin in pinCountMaxper5:\n",
    "        if pin !=\"\":\n",
    "            if pinsynonymsdict[pin][0]==\"否\":\n",
    "                if pinsynonymsdict[pin][1:] not in dienfeaturescore:\n",
    "                    dienfeaturescore[pinsynonymsdict[pin][1:]]=0\n",
    "                dienfeaturescore[pinsynonymsdict[pin][1:]]-=round(pinCountMaxper5[pin]/N,2)*1\n",
    "            else:\n",
    "                if pinsynonymsdict[pin] not in dienfeaturescore:\n",
    "                    dienfeaturescore[pinsynonymsdict[pin]]=0\n",
    "                dienfeaturescore[pinsynonymsdict[pin]]+=round(pinCountMaxper5[pin]/N,2)\n",
    "    if len(dienfeaturescore)==0:\n",
    "        dienfeaturescore[\"無評\"]=1\n",
    "    featurescores.append(dienfeaturescore)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將上述屬性結合成一個大分析表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BigAnalyzeTable=[]\n",
    "for name,style,Ncomment,contentcut,wordCount,TFIDF,pinCountMax5,score,featurescore,introduction,coordinate in zip(dienlist,stylelist,Npartpin,pincutlist,wordCountlist,TF_IDFlist,pinCountMaxper5list,dienscorelist,featurescores,introductionlist,coordinatelist):\n",
    "    dien={}\n",
    "    dien['name']=name\n",
    "    dien['style']=style\n",
    "    dien['Ncomment']=Ncomment\n",
    "    dien['contentcut']=contentcut\n",
    "    dien['wordCount']=wordCount\n",
    "    dien['TF_IDF']=TFIDF\n",
    "    dien['pinCountMaxper5']=pinCountMax5\n",
    "    dien['score']=score\n",
    "    dien['featurescores']=featurescore\n",
    "    dien['tags']=[tag[0] for tag in Counter(TFIDF).most_common(5)]\n",
    "    \n",
    "    dien['introduction']=introduction\n",
    "    dien['coordinate']=coordinate\n",
    "    \n",
    "    \n",
    "    BigAnalyzeTable.append(dien)\n",
    "\n",
    "\n",
    "# dienlist\n",
    "# stylelist\n",
    "# Ncommentlist\n",
    "# pincutlist\n",
    "# wordCountlist\n",
    "# TF_IDFlist\n",
    "# pinCountMaxper5list\n",
    "# dienscorelist\n",
    "# featurescores\n",
    "\n",
    "\n",
    "#店家種類字典introductionlist\n",
    "# introductionlist = [dien[\"introduction\"] for dien in ipeenjson]\n",
    "\n",
    "#店家種類字典coordinatelist\n",
    "# coordinatelist = [dien['coordinate'] for dien in ipeenjson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將每個自定義的評價詞做正規化評分、並且將分數達標者做為標籤貼上!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#算出每個評論的評論數N時的 最大值b 最小值g for正規化\n",
    "\n",
    "\n",
    "#allpin=評論詞list\n",
    "allpin=set([line.split(\",\")[1] for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\" and line.split(\",\")[1][0]!=\"否\"])\n",
    "standard={}\n",
    "\n",
    "#standard為正規化所需用的值\n",
    "for pin in allpin:\n",
    "    for rang in [(0,5),(5,10),(10,15),(15,100)]:\n",
    "        get={}\n",
    "        values=[dien['featurescores'][pin] for dien in BigAnalyzeTable if pin in dien['featurescores'] and dien[\"Ncomment\"]>rang[0] and dien[\"Ncomment\"]<=rang[1]]\n",
    "        b=0\n",
    "        g=0\n",
    "        for value in values:\n",
    "            if value <b:\n",
    "                b=round(value,1)\n",
    "            if value >g:\n",
    "                g=round(value,1)\n",
    "        get[pin+str(rang[0])]=((g+b)/2,g-(g+b)/2)\n",
    "        standard.update(get)\n",
    "        print(pin+\"+\"+str(rang[0])+\"\\t\"+str(g)+\"\\t\"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#進行正規化的處理\n",
    "for dien in BigAnalyzeTable:\n",
    "    N=dien['Ncomment']\n",
    "    for feature in dien['featurescores']:\n",
    "        if feature !=\"無評\":\n",
    "            if N<6:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(0)][1],2)\n",
    "            elif N<11 and N>=6:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(5)][1],2)\n",
    "            elif N<16 and N>=11:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(10)][1],2)\n",
    "            else:\n",
    "                dien['featurescores'][feature]=round((dien['featurescores'][feature])/standard[feature+str(15)][1],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化後，每個屬性的評價區間都為2! 但未避免有些沒被負評的店判斷成負評，不將中間值移至0的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "allpin=[line.split(\",\")[1] for line in mydict.split(\"\\n\") if line.split(\",\")[0]!=\"\" and line.split(\",\")[1][0]!=\"否\"]\n",
    "standard={}\n",
    "\n",
    "for pin in allpin:\n",
    "    for rang in [(0,5),(5,10),(10,15),(15,100)]:\n",
    "#         get={}\n",
    "        values=[dien['featurescores'][pin] for dien in BigAnalyzeTable if pin in dien['featurescores'] and dien[\"Ncomment\"]>rang[0] and dien[\"Ncomment\"]<=rang[1]]\n",
    "        b=0\n",
    "        g=0\n",
    "        for value in values:\n",
    "            if value <b:\n",
    "                b=round(value,1)\n",
    "            if value >g:\n",
    "                g=round(value,1)\n",
    "#         get[pin+str(rang[0])]=((g+b)/2,g-(g+b)/2)\n",
    "#         standard.update(get)\n",
    "        print(pin+\"+\"+str(rang[0])+\"\\t\"+str(g)+\"\\t\"+str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 貼餐廳評價標籤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipin=[('食物美味','食物不好吃',\"非常好吃\",'非常不好吃'),('划算','價格較高昂',\"非常便宜\",'非常貴')\n",
    "       ,('環境好','環境比較不好',\"環境超棒\",'環境很差'),('服務好','服務較差',\"服務一級棒\",'服務很差')\n",
    "       ,('其他正面情緒','評論有些負面情緒詞',\"網路評論正面情緒非常多\",'網路評論負面情緒很多')]\n",
    "moods=[mood[0] for mood in pipin]\n",
    "for dien in BigAnalyzeTable:\n",
    "    newtag=[]\n",
    "    for feature in dien[\"featurescores\"]:\n",
    "        if feature in moods:\n",
    "            if dien[\"featurescores\"][feature]>1:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[2])\n",
    "            elif dien[\"featurescores\"][feature]>0.4:\n",
    "                newtag.append(feature)\n",
    "            elif dien[\"featurescores\"][feature]<-0.5:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[3])\n",
    "            elif dien[\"featurescores\"][feature]<0.0:\n",
    "                for pinpare in pipin:\n",
    "                    if feature==pinpare[0]:\n",
    "                        newtag.append(pinpare[1])\n",
    "        else:\n",
    "            if dien[\"featurescores\"][feature]>0.7:\n",
    "                newtag.append(feature)\n",
    "                    \n",
    "                    \n",
    "#用set去除重複標籤\n",
    "    dien['tags']=list(set(dien['tags']+newtag))\n",
    "    print(dien['name'])\n",
    "#     print(newtag)\n",
    "    dien['tags'].append(dien['style'])\n",
    "    print(dien['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in BigAnalyzeTable:\n",
    "    if i['score']>30 and i['Ncomment']>10:\n",
    "        print(i['name']+' '+str(i['score']))\n",
    "#         print(i['tags'])\n",
    "        print(i['featurescores'])\n",
    "        print('\\n')\n",
    "gooddien=[i for i in BigAnalyzeTable if i['score']>30 and i['Ncomment']>10]\n",
    "# len(gooddien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./finish/bigtable_1.3.json','w') as f:\n",
    "    json.dump(BigAnalyzeTable,f)\n",
    "with open('D:/Data/JsonData/TainanFood/TainanGoodDien_1.1.json','w') as f:\n",
    "    json.dump(gooddien,f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./finish/bigtable_1.3.json') as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
